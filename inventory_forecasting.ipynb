{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Retail Co. - Inventory Forecasting and Analysis\n",
    "\n",
    "**Project:** Solving Inventory Inefficiencies Using Advanced SQL Analytics with Python Integration\n",
    "\n",
    "**Objective:** Integrate Python forecasting models with SQL data to provide predictive inventory insights and optimize stock levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Database Connection\n",
    "\n",
    "First, we'll import necessary libraries and establish a connection to our SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Database connection parameters\n",
    "db_params = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'inventory_db',\n",
    "    'user': 'inventory_user',\n",
    "    'password': 'secure_password'\n",
    "}\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://{db_params['user']}:{db_params['password']}@{db_params['host']}/{db_params['database']}\")\n",
    "\n",
    "print(\"Database connection established.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Extraction from SQL Views\n",
    "\n",
    "We'll leverage the SQL views we created to extract the data needed for our forecasting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to extract sales trend data from our view\n",
    "sales_trend_query = \"\"\"\n",
    "SELECT * FROM solving_inventory.vw_sales_trend_analysis\n",
    "WHERE month_start >= CURRENT_DATE - INTERVAL '24 months'\n",
    "ORDER BY month_start, store_id, product_id\n",
    "\"\"\"\n",
    "\n",
    "# Load data into pandas DataFrame\n",
    "sales_trend_df = pd.read_sql(sales_trend_query, engine)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Sales Trend Data Sample:\")\n",
    "print(sales_trend_df.head())\n",
    "\n",
    "# Get inventory data\n",
    "inventory_query = \"\"\"\n",
    "SELECT * FROM solving_inventory.vw_inventory_kpi_dashboard\n",
    "ORDER BY region, store_id, category_id\n",
    "\"\"\"\n",
    "\n",
    "inventory_df = pd.read_sql(inventory_query, engine)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\nInventory KPI Data Sample:\")\n",
    "print(inventory_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing for Forecasting\n",
    "\n",
    "We'll prepare the data for time series analysis and forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare time series data for a specific product at a specific store\n",
    "def prepare_time_series(store_id, product_id):\n",
    "    # Filter data for the specific store and product\n",
    "    product_data = sales_trend_df[(sales_trend_df['store_id'] == store_id) & \n",
    "                                 (sales_trend_df['product_id'] == product_id)]\n",
    "    \n",
    "    # Sort by date\n",
    "    product_data = product_data.sort_values('month_start')\n",
    "    \n",
    "    # Set month_start as index\n",
    "    product_data = product_data.set_index('month_start')\n",
    "    \n",
    "    # Return the monthly units sold as a time series\n",
    "    return product_data['monthly_units_sold']\n",
    "\n",
    "# Get a list of top-selling products\n",
    "top_products_query = \"\"\"\n",
    "SELECT store_id, product_id, SUM(monthly_units_sold) as total_units\n",
    "FROM solving_inventory.vw_sales_trend_analysis\n",
    "GROUP BY store_id, product_id\n",
    "ORDER BY total_units DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "top_products = pd.read_sql(top_products_query, engine)\n",
    "print(\"Top Selling Products:\")\n",
    "print(top_products.head())\n",
    "\n",
    "# Select the top product for demonstration\n",
    "sample_store_id = top_products.iloc[0]['store_id']\n",
    "sample_product_id = top_products.iloc[0]['product_id']\n",
    "\n",
    "# Prepare time series data\n",
    "ts_data = prepare_time_series(sample_store_id, sample_product_id)\n",
    "\n",
    "print(f\"\\nTime Series Data for Product {sample_product_id} at Store {sample_store_id}:\")\n",
    "print(ts_data.head())\n",
    "\n",
    "# Plot the time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "ts_data.plot()\n",
    "plt.title(f\"Monthly Sales for Product {sample_product_id} at Store {sample_store_id}\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Units Sold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sample_product_sales.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time Series Decomposition\n",
    "\n",
    "We'll decompose the time series to understand its trend, seasonality, and residual components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we have enough data points\n",
    "if len(ts_data) >= 12:  # Need at least 12 months for yearly seasonality\n",
    "    # Decompose the time series\n",
    "    decomposition = seasonal_decompose(ts_data, model='multiplicative', period=12)\n",
    "    \n",
    "    # Plot the decomposition\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12, 10))\n",
    "    \n",
    "    decomposition.observed.plot(ax=ax1)\n",
    "    ax1.set_title('Observed')\n",
    "    \n",
    "    decomposition.trend.plot(ax=ax2)\n",
    "    ax2.set_title('Trend')\n",
    "    \n",
    "    decomposition.seasonal.plot(ax=ax3)\n",
    "    ax3.set_title('Seasonality')\n",
    "    \n",
    "    decomposition.resid.plot(ax=ax4)\n",
    "    ax4.set_title('Residuals')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"time_series_decomposition.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Time series decomposition completed and saved.\")\n",
    "else:\n",
    "    print(\"Not enough data points for seasonal decomposition. Need at least 12 months.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ARIMA Forecasting Model\n",
    "\n",
    "We'll implement an ARIMA model to forecast future sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit ARIMA model and forecast\n",
    "def fit_arima_and_forecast(time_series, forecast_periods=3):\n",
    "    # Split data into train and test sets\n",
    "    train_size = int(len(time_series) * 0.8)\n",
    "    train, test = time_series[:train_size], time_series[train_size:]\n",
    "    \n",
    "    # Fit ARIMA model - parameters (p,d,q) would ideally be determined through analysis\n",
    "    model = ARIMA(train, order=(1, 1, 1))\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Forecast for test period\n",
    "    forecast = model_fit.forecast(steps=len(test))\n",
    "    \n",
    "    # Calculate error\n",
    "    mse = mean_squared_error(test, forecast)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # Forecast future periods\n",
    "    future_forecast = model_fit.forecast(steps=forecast_periods)\n",
    "    \n",
    "    return {\n",
    "        'train': train,\n",
    "        'test': test,\n",
    "        'forecast': forecast,\n",
    "        'future_forecast': future_forecast,\n",
    "        'rmse': rmse,\n",
    "        'model_summary': model_fit.summary()\n",
    "    }\n",
    "\n",
    "# Apply the function to our sample data\n",
    "if len(ts_data) > 5:  # Ensure we have enough data\n",
    "    forecast_results = fit_arima_and_forecast(ts_data)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"ARIMA Model RMSE: {forecast_results['rmse']:.2f}\")\n",
    "    print(\"\\nFuture Forecast (Next 3 Months):\")\n",
    "    print(forecast_results['future_forecast'])\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot training data\n",
    "    plt.plot(forecast_results['train'].index, forecast_results['train'].values, label='Training Data')\n",
    "    \n",
    "    # Plot test data\n",
    "    plt.plot(forecast_results['test'].index, forecast_results['test'].values, label='Test Data')\n",
    "    \n",
    "    # Plot forecast for test period\n",
    "    plt.plot(forecast_results['test'].index, forecast_results['forecast'], label='Forecast', color='red')\n",
    "    \n",
    "    # Plot future forecast\n",
    "    future_index = pd.date_range(start=ts_data.index[-1], periods=4, freq='M')[1:]\n",
    "    plt.plot(future_index, forecast_results['future_forecast'], label='Future Forecast', color='green', linestyle='--')\n",
    "    \n",
    "    plt.title(f\"ARIMA Forecast for Product {sample_product_id} at Store {sample_store_id}\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Units Sold\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"arima_forecast.png\")\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"Not enough data points for ARIMA modeling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inventory Optimization Recommendations\n",
    "\n",
    "Based on our forecasts, we'll generate inventory optimization recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate inventory recommendations based on forecasts\n",
    "def generate_inventory_recommendations(store_id, product_id, forecast_data, lead_time_days=7, safety_factor=1.5):\n",
    "    # Get product details\n",
    "    product_query = f\"\"\"\n",
    "    SELECT p.*, i.quantity_on_hand, i.quantity_reserved\n",
    "    FROM solving_inventory.Products p\n",
    "    JOIN solving_inventory.Inventory i ON p.product_id = i.product_id\n",
    "    WHERE p.product_id = '{product_id}' AND i.store_id = '{store_id}'\n",
    "    \"\"\"\n",
    "    \n",
    "    product_details = pd.read_sql(product_query, engine)\n",
    "    \n",
    "    if product_details.empty:\n",
    "        return \"Product or store not found.\"\n",
    "    \n",
    "    # Extract relevant details\n",
    "    current_stock = product_details.iloc[0]['quantity_on_hand']\n",
    "    reserved_stock = product_details.iloc[0]['quantity_reserved']\n",
    "    available_stock = current_stock - reserved_stock\n",
    "    unit_cost = product_details.iloc[0]['unit_cost']\n",
    "    \n",
    "    # Calculate average monthly forecast\n",
    "    avg_monthly_forecast = forecast_data['future_forecast'].mean()\n",
    "    \n",
    "    # Convert to daily forecast\n",
    "    avg_daily_forecast = avg_monthly_forecast / 30\n",
    "    \n",
    "    # Calculate optimal reorder point\n",
    "    reorder_point = int((avg_daily_forecast * lead_time_days) + (safety_factor * avg_daily_forecast * np.sqrt(lead_time_days)))\n",
    "    \n",
    "    # Calculate optimal order quantity (EOQ formula simplified)\n",
    "    annual_demand = avg_daily_forecast * 365\n",
    "    holding_cost_percent = 0.25  # Assume 25% annual holding cost\n",
    "    ordering_cost = 50  # Assume $50 per order\n",
    "    \n",
    "    eoq = int(np.sqrt((2 * annual_demand * ordering_cost) / (unit_cost * holding_cost_percent)))\n",
    "    \n",
    "    # Generate recommendations\n",
    "    recommendations = {\n",
    "        'store_id': store_id,\n",
    "        'product_id': product_id,\n",
    "        'current_stock': current_stock,\n",
    "        'available_stock': available_stock,\n",
    "        'avg_monthly_forecast': avg_monthly_forecast,\n",
    "        'avg_daily_forecast': avg_daily_forecast,\n",
    "        'optimal_reorder_point': reorder_point,\n",
    "        'economic_order_quantity': eoq,\n",
    "        'days_of_supply': int(available_stock / avg_daily_forecast) if avg_daily_forecast > 0 else float('inf'),\n",
    "        'recommendation': ''\n",
    "    }\n",
    "    \n",
    "    # Determine recommendation\n",
    "    if available_stock <= reorder_point:\n",
    "        recommendations['recommendation'] = f\"REORDER NEEDED: Place order for {eoq} units. Current stock will last approximately {recommendations['days_of_supply']} days.\"\n",
    "    elif available_stock > (reorder_point * 3):\n",
    "        recommendations['recommendation'] = f\"POTENTIAL OVERSTOCK: Current stock exceeds 3x reorder point. Consider reducing future orders or redistributing {int(available_stock - (reorder_point * 1.5))} units to other locations.\"\n",
    "    else:\n",
    "        recommendations['recommendation'] = f\"STOCK LEVEL ADEQUATE: Current stock will last approximately {recommendations['days_of_supply']} days. Next review in {int(recommendations['days_of_supply'] - lead_time_days)} days.\"\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Generate recommendations for our sample product\n",
    "if 'forecast_results' in locals():\n",
    "    recommendations = generate_inventory_recommendations(sample_store_id, sample_product_id, forecast_results)\n",
    "    \n",
    "    print(\"\\nInventory Optimization Recommendations:\")\n",
    "    for key, value in recommendations.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"Forecast results not available for generating recommendations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Processing for Multiple Products\n",
    "\n",
    "We'll extend our analysis to process multiple products and generate a comprehensive report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process multiple products\n",
    "def batch_process_products(product_list, max_products=5):\n",
    "    results = []\n",
    "    \n",
    "    # Limit the number of products to process\n",
    "    products_to_process = product_list.head(max_products)\n",
    "    \n",
    "    for _, row in products_to_process.iterrows():\n",
    "        store_id = row['store_id']\n",
    "        product_id = row['product_id']\n",
    "        \n",
    "        print(f\"Processing product {product_id} at store {store_id}...\")\n",
    "        \n",
    "        # Prepare time series\n",
    "        ts_data = prepare_time_series(store_id, product_id)\n",
    "        \n",
    "        # Skip if not enough data\n",
    "        if len(ts_data) <= 5:\n",
    "            print(f\"  Skipping due to insufficient data ({len(ts_data)} data points).\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Fit ARIMA model\n",
    "            forecast_results = fit_arima_and_forecast(ts_data)\n",
    "            \n",
    "            # Generate recommendations\n",
    "            recommendations = generate_inventory_recommendations(store_id, product_id, forecast_results)\n",
    "            \n",
    "            # Add to results\n",
    "            results.append(recommendations)\n",
    "            \n",
    "            print(f\"  Processed successfully. Recommendation: {recommendations['recommendation'][:50]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing: {str(e)}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Process top products\n",
    "print(\"Batch processing top products...\")\n",
    "recommendations_df = batch_process_products(top_products)\n",
    "\n",
    "# Display results\n",
    "if not recommendations_df.empty:\n",
    "    print(\"\\nSummary of Recommendations:\")\n",
    "    print(recommendations_df[['product_id', 'current_stock', 'optimal_reorder_point', 'economic_order_quantity']])\n",
    "    \n",
    "    # Save to CSV\n",
    "    recommendations_df.to_csv(\"inventory_recommendations.csv\", index=False)\n",
    "    print(\"\\nRecommendations saved to 'inventory_recommendations.csv'\")\n",
    "else:\n",
    "    print(\"No recommendations generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Integration with SQL Database\n",
    "\n",
    "Finally, we'll write our forecasts and recommendations back to the database for use in dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write forecasts back to database\n",
    "def write_forecasts_to_database(recommendations_df):\n",
    "    if recommendations_df.empty:\n",
    "        return \"No data to write.\"\n",
    "    \n",
    "    try:\n",
    "        # Create a temporary table for forecasts if it doesn't exist\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS solving_inventory.product_forecasts (\n",
    "            forecast_id SERIAL PRIMARY KEY,\n",
    "            store_id VARCHAR(50) NOT NULL,\n",
    "            product_id VARCHAR(50) NOT NULL,\n",
    "            forecast_date DATE NOT NULL DEFAULT CURRENT_DATE,\n",
    "            avg_monthly_forecast DECIMAL(10,2),\n",
    "            avg_daily_forecast DECIMAL(10,2),\n",
    "            optimal_reorder_point INT,\n",
    "            economic_order_quantity INT,\n",
    "            days_of_supply INT,\n",
    "            recommendation TEXT,\n",
    "            CONSTRAINT uq_forecast_store_product UNIQUE (store_id, product_id, forecast_date)\n",
    "        );\n",
    "        \"\"\"\n",
    "        \n",
    "        with engine.connect() as connection:\n",
    "            connection.execute(create_table_query)\n",
    "        \n",
    "        # Write the data to the database\n",
    "        recommendations_df.to_sql('product_forecasts', engine, schema='solving_inventory', \n",
    "                                 if_exists='append', index=False,\n",
    "                                 method='multi', chunksize=100)\n",
    "        \n",
    "        return f\"Successfully wrote {len(recommendations_df)} forecasts to database.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing to database: {str(e)}\"\n",
    "\n",
    "# Write our recommendations to the database\n",
    "if 'recommendations_df' in locals() and not recommendations_df.empty:\n",
    "    # Select only the columns we want to write\n",
    "    forecast_columns = ['store_id', 'product_id', 'avg_monthly_forecast', 'avg_daily_forecast', \n",
    "                        'optimal_reorder_point', 'economic_order_quantity', 'days_of_supply', 'recommendation']\n",
    "    \n",
    "    forecasts_to_write = recommendations_df[forecast_columns]\n",
    "    \n",
    "    result = write_forecasts_to_database(forecasts_to_write)\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"No recommendations available to write to database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "This notebook demonstrates how Python forecasting models can be integrated with SQL data to provide predictive inventory insights. The approach combines:\n",
    "\n",
    "1. **SQL Views** for efficient data extraction and KPI calculation\n",
    "2. **Time Series Analysis** to understand sales patterns and seasonality\n",
    "3. **ARIMA Forecasting** to predict future demand\n",
    "4. **Inventory Optimization** to calculate reorder points and economic order quantities\n",
    "5. **Database Integration** to make forecasts available for dashboards\n",
    "\n",
    "By implementing this solution, Urban Retail Co. can move from reactive to proactive inventory management, reducing stockouts and overstock situations while optimizing working capital."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
